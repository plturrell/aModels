version: "3.9"
services:
  hana:
    build:
      context: ..
      dockerfile: hana/Dockerfile
    environment:
      - HANA_DSN=${HANA_DSN}
      - PORT=8083
    ports:
      - "8083:8083"

  gateway:
    build:
      context: ../gateway
    environment:
      - HANA_URL=http://hana:8083
      - GATEWAY_PORT=8000
      - DEEPAGENTS_URL=http://deepagents:9004
      - DEEP_RESEARCH_URL=http://deep-research:2024
      # Model Configuration - LocalAI only (no external LLM dependencies)
      - LOCALAI_URL=http://localai:8080
    ports:
      - "8000:8000"
    depends_on:
      - hana
      - deepagents

  postgres:
    image: ankane/pgvector:latest
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=amodels
    ports:
      - "5432:5432"

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

  opensearch:
    image: opensearchproject/opensearch:2.14.0
    environment:
      - discovery.type=single-node
      - plugins.security.disabled=true
      - OPENSEARCH_JAVA_OPTS=-Xms1g -Xmx1g
    ulimits:
      nofile:
        soft: 65536
        hard: 65536
    ports:
      - "9200:9200"
      - "9600:9600"

  deepagents:
    build:
      context: ../../services/deepagents
      dockerfile: Dockerfile
    environment:
      - EXTRACT_SERVICE_URL=http://extract-service:19080
      - AGENTFLOW_SERVICE_URL=http://agentflow-service:9001
      - GRAPH_SERVICE_URL=http://graph-service:8081
      # Model Configuration - LocalAI only (no external LLM dependencies)
      - LOCALAI_URL=http://localai:8080
      # Disable external LLM providers
      - ANTHROPIC_API_KEY=
      - OPENAI_API_KEY=
      - DEEPAGENTS_PORT=9004
      # DeepAgents is enabled by default (10/10 integration)
      # Set DEEPAGENTS_ENABLED=false to disable
      - DEEPAGENTS_ENABLED=${DEEPAGENTS_ENABLED:-true}
    ports:
      - "9004:9004"
    depends_on:
      - postgres
      - redis
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9004/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  deep-research:
    build:
      context: ../../
      dockerfile: infrastructure/docker/deep-research/Dockerfile
    environment:
      # Catalog Integration (for tools)
      - CATALOG_URL=http://catalog:8084
      - CATALOG_SPARQL_URL=http://catalog:8084/catalog/sparql
      # Model Configuration - LocalAI only (no external LLM dependencies)
      - LOCALAI_URL=http://localai:8080
      # Disable external LLM providers
      - ANTHROPIC_API_KEY=
      - OPENAI_API_KEY=
      # Search API (optional - can use Tavily or none)
      - SEARCH_API=${SEARCH_API:-none}
      - TAVILY_API_KEY=${TAVILY_API_KEY:-}
      # Research Configuration
      - MAX_RESEARCHER_ITERATIONS=${MAX_RESEARCHER_ITERATIONS:-6}
      - MAX_CONCURRENT_RESEARCH_UNITS=${MAX_CONCURRENT_RESEARCH_UNITS:-5}
      - ALLOW_CLARIFICATION=${ALLOW_CLARIFICATION:-true}
      # LangGraph Configuration
      - LANGGRAPH_API_KEY=${LANGGRAPH_API_KEY:-}
    ports:
      - "8085:2024"
    depends_on:
      - catalog
      - localai
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:2024/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
