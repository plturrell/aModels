services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.15.0
    container_name: elasticsearch
    restart: unless-stopped
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - esdata:/usr/share/elasticsearch/data

  localai:
    build:
      context: ../..
      dockerfile: services/localai/Dockerfile
    image: amodels/localai:latest
    container_name: localai
    restart: unless-stopped
    environment:
      - MODELS_DIR=/models
      - TRANSFORMERS_BASE_URL=http://search-python:8091
      - TRANSFORMERS_MODEL=all-MiniLM-L6-v2
      - DISABLE_VAULTGEMMA_FALLBACK=1
    volumes:
      - ../../models:/models:ro
    ports:
      - "8081:8080"
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]

  search-inference:
    build:
      context: ../..
      dockerfile: legacy/stage3/search/search-inference/Dockerfile
    image: amodels/search-inference:latest
    container_name: search-inference
    restart: unless-stopped
    environment:
      - SEARCH_CONFIG=/workspace/config/search-inference.yaml
      - ELASTICSEARCH_HOST=http://elasticsearch:9200
    volumes:
      - ../../legacy/stage3/search/search-inference/config:/workspace/config:ro
      - ../../models:/workspace/models:ro
    ports:
      - "8090:8090"
    depends_on:
      - localai
      - elasticsearch
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]

  search-python:
    build:
      context: ../..
      dockerfile: legacy/stage3/search/python_service/Dockerfile
    image: amodels/search-python-service:latest
    container_name: search-python
    restart: unless-stopped
    environment:
      - PYTHONUNBUFFERED=1
    # Using baked image contents; mounts disabled to avoid host bind issues
    ports:
      - "8091:8091"
    depends_on:
      - search-inference

  trainer:
    build:
      context: ../..
      dockerfile: data/training/Dockerfile
    image: amodels/training-base:latest
    container_name: training-shell
    restart: unless-stopped
    command: ["sleep", "infinity"]
    working_dir: /workspace
    volumes:
      - ../../tools/scripts:/workspace/scripts:rw
      - ../../configs:/workspace/configs:rw
      - ../../models:/workspace/models:rw
      - ../../data:/workspace/data:rw
      - ../../tools:/workspace/tools:rw
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]

  neo4j:
    image: neo4j:5.18-community
    container_name: neo4j
    restart: unless-stopped
    environment:
      - NEO4J_AUTH=neo4j/amodels123
      - NEO4J_PLUGINS=["apoc"]
      - NEO4J_server_default__listen__address=0.0.0.0
      - NEO4J_server_http_listen__address=0.0.0.0:7474
      - NEO4J_server_bolt_listen__address=0.0.0.0:7687
    ports:
      - "7474:7474"
      - "7687:7687"
    volumes:
      - neo4jdata:/data
      - neo4jlogs:/logs

  postgres:
    image: ankane/pgvector:latest
    container_name: postgres
    restart: unless-stopped
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=amodels
    ports:
      - "5432:5432"
    volumes:
      - postgresdata:/var/lib/postgresql/data

  redis:
    image: redis:7-alpine
    container_name: redis
    restart: unless-stopped
    command: redis-server --appendonly yes
    ports:
      - "6379:6379"
    volumes:
      - redisdata:/data

  extract:
    build:
      context: ../..
      dockerfile: services/extract/Dockerfile
    image: amodels/extract:latest
    container_name: extract-service
    restart: unless-stopped
    environment:
      - PORT=8082
      - GRPC_PORT=9090
      - TRAINING_OUTPUT_DIR=/workspace/data/training/extracts
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USERNAME=neo4j
      - NEO4J_PASSWORD=amodels123
      - POSTGRES_CATALOG_DSN=postgresql://postgres:postgres@postgres:5432/amodels?sslmode=disable
      # DeepAgents is enabled by default (10/10 integration)
      # Set DEEPAGENTS_ENABLED=false to disable
      - DEEPAGENTS_ENABLED=${DEEPAGENTS_ENABLED:-true}
      - DEEPAGENTS_URL=${DEEPAGENTS_URL:-http://deepagents-service:9004}
    volumes:
      - ../../data:/workspace/data:rw
      - ../../logs:/workspace/logs:rw
    ports:
      - "8082:8082"
      - "9090:9090"
      - "8815:8815"
    depends_on:
      - elasticsearch
      - neo4j
      - postgres

  graph:
    build:
      context: ../..
      dockerfile: services/graph/Dockerfile
    image: amodels/graph-server:latest
    container_name: graph-server
    restart: unless-stopped
    environment:
      - GRAPH_CONFIG=/workspace/config/graph.yaml
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USERNAME=neo4j
      - NEO4J_PASSWORD=amodels123
    volumes:
      - ../../configs:/workspace/config:ro
      - ../../artifacts/model-release:/workspace/assets:ro
    ports:
      - "8080:8080"
      - "19080:19080"
    depends_on:
      - extract
      - neo4j
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]

  deepagents:
    build:
      context: ../..
      dockerfile: services/deepagents/Dockerfile
    image: amodels/deepagents:latest
    container_name: deepagents-service
    restart: unless-stopped
    environment:
      - DEEPAGENTS_PORT=9004
      # Service URLs for DeepAgents tools
      - EXTRACT_SERVICE_URL=http://extract-service:8082
      - AGENTFLOW_SERVICE_URL=http://agentflow-service:8001
      - GRAPH_SERVICE_URL=http://graph-server:8080
      # Model Configuration - LocalAI only (no external LLM dependencies)
      - LOCALAI_URL=http://localai:8081
      # Domain name (defaults to "general" which uses phi-3.5-mini via transformers backend)
      # Available domains can be queried at http://localai:8081/v1/domains
      - LOCALAI_MODEL=${LOCALAI_MODEL:-general}
      # Disable external LLM providers
      - ANTHROPIC_API_KEY=
      - OPENAI_API_KEY=
    ports:
      - "9004:9004"
    depends_on:
      - postgres
      - redis
      - localai
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9004/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

networks:
  default:
    driver: bridge

volumes:
  esdata:
  neo4jdata:
  neo4jlogs:
  postgresdata:
  redisdata:
