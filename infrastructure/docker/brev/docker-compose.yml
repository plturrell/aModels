services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.15.0
    container_name: elasticsearch
    restart: unless-stopped
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - esdata:/usr/share/elasticsearch/data

  localai:
    build:
      context: ../..
      dockerfile: services/localai/Dockerfile
    image: amodels/localai:latest
    container_name: localai
    restart: unless-stopped
    environment:
      - MODELS_DIR=/models
      - TRANSFORMERS_BASE_URL=http://search-python:8091
      - TRANSFORMERS_MODEL=all-MiniLM-L6-v2
      - DISABLE_VAULTGEMMA_FALLBACK=1
    volumes:
      - ../../models:/models:ro
    ports:
      - "8081:8080"
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]

  search-inference:
    build:
      context: ../..
      dockerfile: legacy/stage3/search/search-inference/Dockerfile
    image: amodels/search-inference:latest
    container_name: search-inference
    restart: unless-stopped
    environment:
      - SEARCH_CONFIG=/workspace/config/search-inference.yaml
      - ELASTICSEARCH_HOST=http://elasticsearch:9200
    volumes:
      - ../../legacy/stage3/search/search-inference/config:/workspace/config:ro
      - ../../models:/workspace/models:ro
    ports:
      - "8090:8090"
    depends_on:
      - localai
      - elasticsearch
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]

  search-python:
    build:
      context: ../..
      dockerfile: legacy/stage3/search/python_service/Dockerfile
    image: amodels/search-python-service:latest
    container_name: search-python
    restart: unless-stopped
    environment:
      - PYTHONUNBUFFERED=1
    # Using baked image contents; mounts disabled to avoid host bind issues
    ports:
      - "8091:8091"
    depends_on:
      - search-inference

  trainer:
    build:
      context: ../..
      dockerfile: data/training/Dockerfile
    image: amodels/training-base:latest
    container_name: training-shell
    restart: unless-stopped
    command: ["sleep", "infinity"]
    working_dir: /workspace
    volumes:
      - ../../tools/scripts:/workspace/scripts:rw
      - ../../configs:/workspace/configs:rw
      - ../../models:/workspace/models:rw
      - ../../data:/workspace/data:rw
      - ../../tools:/workspace/tools:rw
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]

  extract:
    build:
      context: ../..
      dockerfile: services/extract/Dockerfile
    image: amodels/extract:latest
    container_name: extract-service
    restart: unless-stopped
    environment:
      - PORT=8081
      - GRPC_PORT=9090
      - TRAINING_OUTPUT_DIR=/workspace/data/training/extracts
    volumes:
      - ../../data:/workspace/data:rw
      - ../../logs:/workspace/logs:rw
    ports:
      - "8081:8081"
      - "9090:9090"
    depends_on:
      - elasticsearch

  graph:
    build:
      context: ../..
      dockerfile: legacy/stage3/graph/Dockerfile
    image: amodels/graph-server:latest
    container_name: graph-server
    restart: unless-stopped
    environment:
      - GRAPH_CONFIG=/workspace/config/graph.yaml
      - NEO4J_URI=bolt://localhost:7687
    volumes:
      - ../../configs:/workspace/config:ro
      - ../../artifacts/model-release:/workspace/assets:ro
    ports:
      - "8080:8080"
      - "19080:19080"
    depends_on:
      - extract
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]

networks:
  default:
    driver: bridge

volumes:
  esdata:
