//go:build hana

package storage

import (
	"context"
	"database/sql"
	"encoding/json"
	"fmt"
	"log"
	"time"

	"github.com/plturrell/agenticAiETH/agenticAiETH_layer4_LocalAI/pkg/hanapool"
)

// InferenceLog represents a logged inference request/response
type InferenceLog struct {
	ID           int64                  `json:"id"`
	RequestID    string                 `json:"request_id"`
	Model        string                 `json:"model"`
	Domain       string                 `json:"domain"`
	Prompt       string                 `json:"prompt"`
	Response     string                 `json:"response"`
	TokensUsed   int                    `json:"tokens_used"`
	LatencyMs    int64                  `json:"latency_ms"`
	Temperature  float64                `json:"temperature"`
	MaxTokens    int                    `json:"max_tokens"`
	CacheHit     bool                   `json:"cache_hit"`
	UserID       string                 `json:"user_id,omitempty"`
	SessionID    string                 `json:"session_id,omitempty"`
	RequestTime  time.Time              `json:"request_time"`
	ResponseTime time.Time              `json:"response_time"`
	Error        string                 `json:"error,omitempty"`
	Metadata     map[string]interface{} `json:"metadata,omitempty"`
}

// ModelMetrics tracks performance metrics for each model
type ModelMetrics struct {
	Model         string    `json:"model"`
	TotalRequests int64     `json:"total_requests"`
	TotalTokens   int64     `json:"total_tokens"`
	AvgLatencyMs  float64   `json:"avg_latency_ms"`
	CacheHitRate  float64   `json:"cache_hit_rate"`
	ErrorRate     float64   `json:"error_rate"`
	LastUpdated   time.Time `json:"last_updated"`
}

// HANALogger provides HANA-backed logging for LocalAI inference
type HANALogger struct {
	pool *hanapool.Pool
}

// NewHANALogger creates a new HANA logger
func NewHANALogger(pool *hanapool.Pool) *HANALogger {
	return &HANALogger{pool: pool}
}

func (l *HANALogger) poolAvailable() bool {
	if l == nil || l.pool == nil {
		return false
	}
	return l.pool.GetDB() != nil
}

// CreateTables creates the necessary tables for inference logging
func (l *HANALogger) CreateTables(ctx context.Context) error {
	if !l.poolAvailable() {
		return fmt.Errorf("hana pool not configured")
	}

	createInferenceLogsSQL := `
CREATE COLUMN TABLE inference_logs (
	id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
	request_id NVARCHAR(255) NOT NULL,
	model NVARCHAR(100) NOT NULL,
	domain NVARCHAR(100),
	prompt NCLOB,
	response NCLOB,
	tokens_used INTEGER,
	latency_ms BIGINT,
	temperature DECIMAL(5,2),
	max_tokens INTEGER,
	cache_hit BOOLEAN DEFAULT FALSE,
	user_id NVARCHAR(255),
	session_id NVARCHAR(255),
	request_time TIMESTAMP,
	response_time TIMESTAMP,
	error NCLOB,
	metadata NCLOB,
	created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
)
`
	if _, err := l.pool.Execute(ctx, createInferenceLogsSQL); err != nil && !isAlreadyExistsError(err) {
		return fmt.Errorf("failed to create inference_logs table: %w", err)
	}

	createModelMetricsSQL := `
CREATE COLUMN TABLE model_metrics (
	id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
	model NVARCHAR(100) NOT NULL UNIQUE,
	total_requests BIGINT DEFAULT 0,
	total_tokens BIGINT DEFAULT 0,
	avg_latency_ms DECIMAL(10,2) DEFAULT 0,
	cache_hit_rate DECIMAL(5,4) DEFAULT 0,
	error_rate DECIMAL(5,4) DEFAULT 0,
	last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
	created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
)
`
	if _, err := l.pool.Execute(ctx, createModelMetricsSQL); err != nil && !isAlreadyExistsError(err) {
		return fmt.Errorf("failed to create model_metrics table: %w", err)
	}

	createCacheEntriesSQL := `
CREATE COLUMN TABLE cache_entries (
	id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
	cache_key NVARCHAR(255) NOT NULL UNIQUE,
	prompt_hash NVARCHAR(64) NOT NULL,
	model NVARCHAR(100) NOT NULL,
	domain NVARCHAR(100),
	response NCLOB NOT NULL,
	tokens_used INTEGER,
	temperature DECIMAL(5,2),
	max_tokens INTEGER,
	created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
	expires_at TIMESTAMP,
	access_count INTEGER DEFAULT 0,
	last_accessed TIMESTAMP
)
`
	if _, err := l.pool.Execute(ctx, createCacheEntriesSQL); err != nil && !isAlreadyExistsError(err) {
		return fmt.Errorf("failed to create cache_entries table: %w", err)
	}

	indexes := []string{
		"CREATE INDEX idx_logs_request_id ON inference_logs (request_id)",
		"CREATE INDEX idx_logs_model ON inference_logs (model)",
		"CREATE INDEX idx_logs_domain ON inference_logs (domain)",
		"CREATE INDEX idx_logs_request_time ON inference_logs (request_time)",
		"CREATE INDEX idx_logs_user_id ON inference_logs (user_id)",
		"CREATE INDEX idx_metrics_model ON model_metrics (model)",
		"CREATE INDEX idx_cache_entries_key ON cache_entries (cache_key)",
		"CREATE INDEX idx_cache_entries_hash ON cache_entries (prompt_hash)",
		"CREATE INDEX idx_cache_entries_model ON cache_entries (model)",
		"CREATE INDEX idx_cache_entries_expires ON cache_entries (expires_at)",
	}

	for _, stmt := range indexes {
		if _, err := l.pool.Execute(ctx, stmt); err != nil && !isAlreadyExistsError(err) {
			fmt.Printf("âš ï¸  HANA logger index creation failed: %v\n", err)
		}
	}

	log.Println("âœ… HANA logger tables verified successfully")
	return nil
}

// LogInference logs an inference request/response to HANA
func (l *HANALogger) LogInference(ctx context.Context, logEntry *InferenceLog) error {
	if !l.poolAvailable() {
		return fmt.Errorf("hana pool not configured")
	}

	// Convert metadata to JSON
	metadataJSON, err := json.Marshal(logEntry.Metadata)
	if err != nil {
		metadataJSON = []byte("{}")
	}

	query := `
		INSERT INTO inference_logs (
			request_id, model, domain, prompt, response, tokens_used, 
			latency_ms, temperature, max_tokens, cache_hit, user_id, 
			session_id, request_time, response_time, error, metadata
		) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
	`

	_, err = l.pool.Execute(ctx, query,
		logEntry.RequestID,
		logEntry.Model,
		logEntry.Domain,
		logEntry.Prompt,
		logEntry.Response,
		logEntry.TokensUsed,
		logEntry.LatencyMs,
		logEntry.Temperature,
		logEntry.MaxTokens,
		logEntry.CacheHit,
		logEntry.UserID,
		logEntry.SessionID,
		logEntry.RequestTime,
		logEntry.ResponseTime,
		logEntry.Error,
		string(metadataJSON),
	)

	if err != nil {
		return fmt.Errorf("failed to log inference: %w", err)
	}

	// Update model metrics asynchronously
	go l.updateModelMetrics(context.Background(), logEntry)

	return nil
}

// GetModelMetrics retrieves performance metrics for a model
func (l *HANALogger) GetModelMetrics(ctx context.Context, model string) (*ModelMetrics, error) {
	if !l.poolAvailable() {
		return nil, fmt.Errorf("hana pool not configured")
	}

	query := `
		SELECT model, total_requests, total_tokens, avg_latency_ms, 
		       cache_hit_rate, error_rate, last_updated
		FROM model_metrics 
		WHERE model = ?
	`

	row := l.pool.QueryRow(ctx, query, model)

	metrics := &ModelMetrics{}
	err := row.Scan(
		&metrics.Model,
		&metrics.TotalRequests,
		&metrics.TotalTokens,
		&metrics.AvgLatencyMs,
		&metrics.CacheHitRate,
		&metrics.ErrorRate,
		&metrics.LastUpdated,
	)

	if err != nil {
		if err == sql.ErrNoRows {
			return &ModelMetrics{Model: model}, nil
		}
		return nil, fmt.Errorf("failed to get model metrics: %w", err)
	}

	return metrics, nil
}

// GetRecentInferences retrieves recent inference logs
func (l *HANALogger) GetRecentInferences(ctx context.Context, limit int) ([]*InferenceLog, error) {
	if !l.poolAvailable() {
		return nil, fmt.Errorf("hana pool not configured")
	}

	query := `
		SELECT id, request_id, model, domain, prompt, response, tokens_used,
		       latency_ms, temperature, max_tokens, cache_hit, user_id,
		       session_id, request_time, response_time, error, metadata
		FROM inference_logs 
		ORDER BY request_time DESC 
		LIMIT ?
	`

	rows, err := l.pool.Query(ctx, query, limit)
	if err != nil {
		return nil, fmt.Errorf("failed to get recent inferences: %w", err)
	}
	defer rows.Close()

	var logs []*InferenceLog
	for rows.Next() {
		logEntry := &InferenceLog{}
		var metadataJSON string

		err := rows.Scan(
			&logEntry.ID,
			&logEntry.RequestID,
			&logEntry.Model,
			&logEntry.Domain,
			&logEntry.Prompt,
			&logEntry.Response,
			&logEntry.TokensUsed,
			&logEntry.LatencyMs,
			&logEntry.Temperature,
			&logEntry.MaxTokens,
			&logEntry.CacheHit,
			&logEntry.UserID,
			&logEntry.SessionID,
			&logEntry.RequestTime,
			&logEntry.ResponseTime,
			&logEntry.Error,
			&metadataJSON,
		)
		if err != nil {
			return nil, fmt.Errorf("failed to scan inference log: %w", err)
		}

		// Parse metadata JSON
		if metadataJSON != "" {
			json.Unmarshal([]byte(metadataJSON), &logEntry.Metadata)
		}

		logs = append(logs, logEntry)
	}

	return logs, nil
}

// updateModelMetrics updates model performance metrics
func (l *HANALogger) updateModelMetrics(ctx context.Context, logEntry *InferenceLog) {
	if !l.poolAvailable() {
		return
	}

	// Calculate metrics for this model
	query := `
		SELECT 
			COUNT(*) as total_requests,
			SUM(tokens_used) as total_tokens,
			AVG(latency_ms) as avg_latency_ms,
			AVG(CASE WHEN cache_hit = true THEN 1.0 ELSE 0.0 END) as cache_hit_rate,
			AVG(CASE WHEN error IS NOT NULL AND error != '' THEN 1.0 ELSE 0.0 END) as error_rate
		FROM inference_logs 
		WHERE model = ? AND request_time >= DATEADD(day, -30, CURRENT_TIMESTAMP)
	`

	row := l.pool.QueryRow(ctx, query, logEntry.Model)

	var totalRequests, totalTokens int64
	var avgLatencyMs, cacheHitRate, errorRate float64

	err := row.Scan(&totalRequests, &totalTokens, &avgLatencyMs, &cacheHitRate, &errorRate)
	if err != nil {
		log.Printf("Failed to calculate model metrics: %v", err)
		return
	}

	// Upsert model metrics
	upsertQuery := `
		MERGE INTO model_metrics AS target
		USING (SELECT ? as model, ? as total_requests, ? as total_tokens, 
		              ? as avg_latency_ms, ? as cache_hit_rate, ? as error_rate,
		              CURRENT_TIMESTAMP as last_updated) AS source
		ON target.model = source.model
		WHEN MATCHED THEN
			UPDATE SET total_requests = source.total_requests,
			           total_tokens = source.total_tokens,
			           avg_latency_ms = source.avg_latency_ms,
			           cache_hit_rate = source.cache_hit_rate,
			           error_rate = source.error_rate,
			           last_updated = source.last_updated
		WHEN NOT MATCHED THEN
			INSERT (model, total_requests, total_tokens, avg_latency_ms, 
			        cache_hit_rate, error_rate, last_updated)
			VALUES (source.model, source.total_requests, source.total_tokens,
			        source.avg_latency_ms, source.cache_hit_rate, source.error_rate,
			        source.last_updated)
	`

	_, err = l.pool.Execute(ctx, upsertQuery,
		logEntry.Model, totalRequests, totalTokens, avgLatencyMs, cacheHitRate, errorRate)
	if err != nil {
		log.Printf("Failed to update model metrics: %v", err)
	}
}

// CleanupOldLogs removes old inference logs to manage storage
func (l *HANALogger) CleanupOldLogs(ctx context.Context, olderThanDays int) error {
	if !l.poolAvailable() {
		return fmt.Errorf("hana pool not configured")
	}

	query := `
		DELETE FROM inference_logs 
		WHERE request_time < DATEADD(day, -?, CURRENT_TIMESTAMP)
	`

	result, err := l.pool.Execute(ctx, query, olderThanDays)
	if err != nil {
		return fmt.Errorf("failed to cleanup old logs: %w", err)
	}

	rowsAffected, _ := result.RowsAffected()
	log.Printf("ðŸ§¹ Cleaned up %d old inference logs", rowsAffected)

	return nil
}
