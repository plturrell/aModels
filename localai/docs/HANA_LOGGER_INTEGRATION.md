# HANA Logger Integration for LocalAI

## Overview

The HANA Logger provides comprehensive logging and monitoring capabilities for LocalAI inference requests and responses. It integrates seamlessly with the VaultGemma server to capture detailed metrics, performance data, and user interactions.

## Features

### Core Logging Capabilities

- **Inference Request/Response Logging**: Captures all inference requests and responses with detailed metadata
- **Performance Metrics**: Tracks latency, token usage, and throughput for each model
- **Cache Hit Tracking**: Monitors cache effectiveness and hit rates
- **Error Logging**: Captures and logs inference errors with detailed context
- **User Session Tracking**: Associates requests with users and sessions
- **Metadata Storage**: Stores custom metadata for each inference

### Advanced Features

- **Model Performance Analytics**: Aggregated metrics per model including:
  - Total requests and tokens
  - Average latency
  - Cache hit rates
  - Error rates
- **Historical Data**: Maintains inference history for analysis and debugging
- **Automatic Cleanup**: Configurable cleanup of old logs to manage storage
- **Asynchronous Logging**: Non-blocking logging to avoid performance impact

## Architecture

### Database Schema

The HANA logger creates three main tables:

#### 1. inference_logs
```sql
CREATE TABLE inference_logs (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    request_id NVARCHAR(255) NOT NULL,
    model NVARCHAR(100) NOT NULL,
    domain NVARCHAR(100),
    prompt NCLOB,
    response NCLOB,
    tokens_used INTEGER,
    latency_ms BIGINT,
    temperature DECIMAL(5,2),
    max_tokens INTEGER,
    cache_hit BOOLEAN DEFAULT FALSE,
    user_id NVARCHAR(255),
    session_id NVARCHAR(255),
    request_time TIMESTAMP,
    response_time TIMESTAMP,
    error NCLOB,
    metadata NCLOB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
)
```

#### 2. model_metrics
```sql
CREATE TABLE model_metrics (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    model NVARCHAR(100) NOT NULL UNIQUE,
    total_requests BIGINT DEFAULT 0,
    total_tokens BIGINT DEFAULT 0,
    avg_latency_ms DECIMAL(10,2) DEFAULT 0,
    cache_hit_rate DECIMAL(5,4) DEFAULT 0,
    error_rate DECIMAL(5,4) DEFAULT 0,
    last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP
)
```

#### 3. cache_entries
```sql
CREATE TABLE cache_entries (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    cache_key NVARCHAR(255) NOT NULL UNIQUE,
    prompt_hash NVARCHAR(64) NOT NULL,
    model NVARCHAR(100) NOT NULL,
    domain NVARCHAR(100),
    response NCLOB NOT NULL,
    tokens_used INTEGER,
    temperature DECIMAL(5,2),
    max_tokens INTEGER,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    expires_at TIMESTAMP,
    access_count INTEGER DEFAULT 0,
    last_accessed TIMESTAMP
)
```

## Integration

### Server Integration

The HANA logger is integrated into the VaultGemma server:

```go
type VaultGemmaServer struct {
    // ... other fields
    hanaLogger *storage.HANALogger
    hanaCache  *storage.HANACache
    // ... other fields
}
```

### Initialization

```go
// Create HANA logger and cache
hanaLogger := storage.NewHANALogger(hanaPool)
hanaCache := storage.NewHANACache(hanaPool)

// Create tables if they don't exist
ctx := context.Background()
if err := hanaLogger.CreateTables(ctx); err != nil {
    log.Printf("‚ö†Ô∏è Failed to create HANA logger tables: %v", err)
}

// Initialize server with HANA logger
server := &VaultGemmaServer{
    hanaLogger: hanaLogger,
    hanaCache:  hanaCache,
    // ... other fields
}
```

### Request Logging

The server automatically logs all inference requests:

```go
// Log to HANA if available
if s.hanaLogger != nil {
    requestID := fmt.Sprintf("req_%d", time.Now().UnixNano())
    logEntry := &storage.InferenceLog{
        RequestID:    requestID,
        Model:        modelKey,
        Domain:       domain,
        Prompt:       prompt,
        Response:     response,
        TokensUsed:   tokensUsed,
        LatencyMs:    latencyMs,
        Temperature:  temperature,
        MaxTokens:    maxTokens,
        CacheHit:     cacheHit,
        UserID:       userID,
        SessionID:    sessionID,
        RequestTime:  requestTime,
        ResponseTime: responseTime,
        Error:        error,
        Metadata:     metadata,
    }

    // Log asynchronously to avoid blocking response
    go func() {
        if err := s.hanaLogger.LogInference(context.Background(), logEntry); err != nil {
            log.Printf("‚ö†Ô∏è Failed to log inference to HANA: %v", err)
        }
    }()
}
```

## Usage

### Basic Logging

```go
// Create HANA logger
logger := storage.NewHANALogger(hanaPool)

// Initialize tables
ctx := context.Background()
err := logger.CreateTables(ctx)
if err != nil {
    log.Fatal(err)
}

// Log an inference
logEntry := &storage.InferenceLog{
    RequestID:    "req_123456",
    Model:        "vaultgemma-1b",
    Domain:       "general",
    Prompt:       "What is AI?",
    Response:     "AI is artificial intelligence...",
    TokensUsed:   150,
    LatencyMs:    2500,
    Temperature:  0.7,
    MaxTokens:    1000,
    CacheHit:     false,
    UserID:       "user123",
    SessionID:    "session456",
    RequestTime:  time.Now().Add(-5 * time.Second),
    ResponseTime: time.Now(),
    Metadata: map[string]interface{}{
        "user_agent": "web-client",
        "ip_address": "192.168.1.100",
    },
}

err = logger.LogInference(ctx, logEntry)
if err != nil {
    log.Printf("Failed to log inference: %v", err)
}
```

### Retrieving Metrics

```go
// Get model metrics
metrics, err := logger.GetModelMetrics(ctx, "vaultgemma-1b")
if err != nil {
    log.Printf("Failed to get metrics: %v", err)
    return
}

fmt.Printf("Model: %s\n", metrics.Model)
fmt.Printf("Total Requests: %d\n", metrics.TotalRequests)
fmt.Printf("Cache Hit Rate: %.2f%%\n", metrics.CacheHitRate*100)
fmt.Printf("Error Rate: %.2f%%\n", metrics.ErrorRate*100)
```

### Retrieving Recent Logs

```go
// Get recent inference logs
logs, err := logger.GetRecentInferences(ctx, 10)
if err != nil {
    log.Printf("Failed to get recent logs: %v", err)
    return
}

for _, log := range logs {
    fmt.Printf("Request: %s, Model: %s, Tokens: %d\n", 
        log.RequestID, log.Model, log.TokensUsed)
}
```

### Error Logging

```go
// Log an inference with error
logEntry := &storage.InferenceLog{
    RequestID:    "req_error_123",
    Model:        "vaultgemma-1b",
    Domain:       "general",
    Prompt:       "Invalid prompt",
    Response:     "",
    TokensUsed:   0,
    LatencyMs:    100,
    Temperature:  0.7,
    MaxTokens:    1000,
    CacheHit:     false,
    UserID:       "user123",
    SessionID:    "session456",
    RequestTime:  time.Now().Add(-2 * time.Second),
    ResponseTime: time.Now(),
    Error:        "Model inference failed: timeout",
    Metadata: map[string]interface{}{
        "error_type": "timeout",
        "retry_count": 3,
    },
}

err = logger.LogInference(ctx, logEntry)
```

## Monitoring and Analytics

### Performance Metrics

The HANA logger automatically calculates and maintains performance metrics:

- **Total Requests**: Number of requests per model
- **Total Tokens**: Total tokens processed per model
- **Average Latency**: Average response time per model
- **Cache Hit Rate**: Percentage of requests served from cache
- **Error Rate**: Percentage of requests that resulted in errors

### Querying Data

```sql
-- Get model performance summary
SELECT 
    model,
    total_requests,
    total_tokens,
    avg_latency_ms,
    cache_hit_rate,
    error_rate
FROM model_metrics
ORDER BY total_requests DESC;

-- Get recent inference logs
SELECT 
    request_id,
    model,
    domain,
    tokens_used,
    latency_ms,
    cache_hit,
    request_time
FROM inference_logs
ORDER BY request_time DESC
LIMIT 100;

-- Get cache performance
SELECT 
    model,
    COUNT(*) as total_entries,
    AVG(access_count) as avg_access_count,
    COUNT(CASE WHEN expires_at > CURRENT_TIMESTAMP THEN 1 END) as active_entries
FROM cache_entries
GROUP BY model;
```

### Analytics Queries

```sql
-- Model usage by domain
SELECT 
    model,
    domain,
    COUNT(*) as request_count,
    AVG(latency_ms) as avg_latency,
    AVG(tokens_used) as avg_tokens
FROM inference_logs
WHERE request_time >= DATEADD(day, -7, CURRENT_TIMESTAMP)
GROUP BY model, domain
ORDER BY request_count DESC;

-- Cache effectiveness
SELECT 
    model,
    AVG(CASE WHEN cache_hit = true THEN 1.0 ELSE 0.0 END) as cache_hit_rate,
    COUNT(*) as total_requests
FROM inference_logs
WHERE request_time >= DATEADD(day, -1, CURRENT_TIMESTAMP)
GROUP BY model;

-- Error analysis
SELECT 
    model,
    error,
    COUNT(*) as error_count
FROM inference_logs
WHERE error IS NOT NULL AND error != ''
  AND request_time >= DATEADD(day, -1, CURRENT_TIMESTAMP)
GROUP BY model, error
ORDER BY error_count DESC;
```

## Maintenance

### Cleanup Operations

```go
// Clean up old logs (older than 30 days)
err := logger.CleanupOldLogs(ctx, 30)
if err != nil {
    log.Printf("Failed to cleanup old logs: %v", err)
}
```

### Health Checks

```go
// Check if logger is working
metrics, err := logger.GetModelMetrics(ctx, "vaultgemma-1b")
if err != nil {
    log.Printf("HANA logger health check failed: %v", err)
    // Handle error or fallback
}
```

## Configuration

### Environment Variables

```bash
# HANA connection
HANA_HOST=your-hana-host
HANA_PORT=443
HANA_USER=your-username
HANA_PASSWORD=your-password
HANA_DATABASE=your-database
HANA_ENCRYPT=true
```

### Server Configuration

```go
// Configure HANA pool
config := &hanapool.Config{
    Host:     os.Getenv("HANA_HOST"),
    Port:     os.Getenv("HANA_PORT"),
    User:     os.Getenv("HANA_USER"),
    Password: os.Getenv("HANA_PASSWORD"),
    Database: os.Getenv("HANA_DATABASE"),
    Encrypt:  os.Getenv("HANA_ENCRYPT") == "true",
}

// Create HANA pool
hanaPool, err := hanapool.NewPool(config)
if err != nil {
    log.Printf("‚ö†Ô∏è Failed to initialize HANA pool: %v", err)
    log.Printf("üí° Continuing without HANA logging and caching")
}
```

## Best Practices

### Performance Optimization

1. **Asynchronous Logging**: Always log asynchronously to avoid blocking responses
2. **Batch Operations**: Consider batching multiple log entries for better performance
3. **Connection Pooling**: Use connection pooling for database operations
4. **Indexing**: Ensure proper indexing on frequently queried columns

### Error Handling

1. **Graceful Degradation**: Continue operation even if logging fails
2. **Error Logging**: Log logging errors to avoid silent failures
3. **Retry Logic**: Implement retry logic for transient failures
4. **Fallback Mechanisms**: Provide fallback logging mechanisms

### Security Considerations

1. **Data Privacy**: Be careful with sensitive data in prompts and responses
2. **Access Control**: Implement proper access controls for log data
3. **Data Retention**: Implement appropriate data retention policies
4. **Encryption**: Use encryption for sensitive log data

### Monitoring

1. **Health Checks**: Regular health checks for the logging system
2. **Performance Monitoring**: Monitor logging performance impact
3. **Storage Monitoring**: Monitor storage usage and growth
4. **Error Monitoring**: Monitor logging errors and failures

## Troubleshooting

### Common Issues

1. **Connection Failures**: Check HANA connection configuration
2. **Table Creation Errors**: Verify database permissions
3. **Performance Issues**: Check database indexes and query performance
4. **Storage Issues**: Monitor storage usage and implement cleanup

### Debugging

```go
// Enable debug logging
log.SetLevel(log.DebugLevel)

// Check table existence
query := `
    SELECT COUNT(*) FROM M_TABLES 
    WHERE SCHEMA_NAME = CURRENT_SCHEMA 
    AND TABLE_NAME = 'INFERENCE_LOGS'
`

var count int
err := pool.QueryRow(ctx, query).Scan(&count)
if err != nil {
    log.Printf("Failed to check table existence: %v", err)
}
```

## Future Enhancements

### Planned Features

- **Real-time Dashboards**: Live monitoring dashboards
- **Alerting**: Automated alerts for performance issues
- **Advanced Analytics**: Machine learning for log analysis
- **Data Export**: Export capabilities for external analysis
- **Custom Metrics**: Support for custom business metrics

### Integration Opportunities

- **Prometheus Metrics**: Export metrics to Prometheus
- **Grafana Dashboards**: Visual monitoring dashboards
- **ELK Stack**: Integration with Elasticsearch, Logstash, and Kibana
- **Data Lakes**: Integration with data lake solutions

## Conclusion

The HANA Logger provides a comprehensive solution for monitoring and analyzing LocalAI inference operations. With its rich feature set, performance optimizations, and seamless integration, it enables effective monitoring, debugging, and optimization of AI inference systems.

The system is designed to be scalable, maintainable, and efficient, providing the foundation for production-ready AI inference monitoring and analytics.
