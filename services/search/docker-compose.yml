version: "3.9"

services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.15.1
    container_name: search-elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
    ports:
      - "9200:9200"
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 40s
    volumes:
      - es-data:/usr/share/elasticsearch/data

  redis:
    image: redis:7.4-alpine
    container_name: search-redis
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  localai:
    image: ghcr.io/go-skynet/local-ai:latest
    container_name: search-localai
    environment:
      - LOCALAI_PORT=8080
    volumes:
      - localai-models:/build/models
    healthcheck:
      test: ["CMD", "curl", "-sf", "http://localhost:8080/healthz"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  search-inference:
    build: ./search-inference
    container_name: search-inference
    depends_on:
      elasticsearch:
        condition: service_healthy
      redis:
        condition: service_healthy
      localai:
        condition: service_started
    environment:
      - LOCALAI_BASE_URL=http://localai:8080
      - ELASTICSEARCH_ADDRESSES=http://elasticsearch:9200
      - REDIS_ADDR=redis:6379
      - REDIS_DB=0
      - SEARCH_PRIVACY_LEVEL=medium
      - AUTH_ENABLED=${AUTH_ENABLED:-false}
      - API_KEYS=${API_KEYS:-}
      - RATE_LIMIT_ENABLED=${RATE_LIMIT_ENABLED:-true}
      - RATE_LIMIT_PER_MINUTE=${RATE_LIMIT_PER_MINUTE:-60}
    ports:
      - "8090:8090"

  python-service:
    build: ./python_service
    container_name: search-python-service
    depends_on:
      search-inference:
        condition: service_started
      elasticsearch:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      - GO_SEARCH_URL=http://search-inference:8090
      - ELASTICSEARCH_URLS=http://elasticsearch:9200
      - REDIS_URL=redis://redis:6379/0
      - PORT=8091
      - AUTH_ENABLED=${AUTH_ENABLED:-false}
      - API_KEYS=${API_KEYS:-}
      - RATE_LIMIT_ENABLED=${RATE_LIMIT_ENABLED:-true}
      - RATE_LIMIT_PER_MINUTE=${RATE_LIMIT_PER_MINUTE:-60}
    ports:
      - "8081:8091"

volumes:
  es-data:
  localai-models:
