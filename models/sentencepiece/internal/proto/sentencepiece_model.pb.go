// Copyright 2016 Google Inc.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.!

// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.10
// 	protoc        v6.32.1
// source: sentencepiece_model.proto

package proto

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// Model type. only have UNIGRAM now.
type TrainerSpec_ModelType int32

const (
	TrainerSpec_UNIGRAM TrainerSpec_ModelType = 1 // Unigram language model with dynamic algorithm
	TrainerSpec_BPE     TrainerSpec_ModelType = 2 // Byte Pair Encoding
	TrainerSpec_WORD    TrainerSpec_ModelType = 3 // Delimitered by whitespace.
	TrainerSpec_CHAR    TrainerSpec_ModelType = 4 // tokenizes into character sequence
)

// Enum value maps for TrainerSpec_ModelType.
var (
	TrainerSpec_ModelType_name = map[int32]string{
		1: "UNIGRAM",
		2: "BPE",
		3: "WORD",
		4: "CHAR",
	}
	TrainerSpec_ModelType_value = map[string]int32{
		"UNIGRAM": 1,
		"BPE":     2,
		"WORD":    3,
		"CHAR":    4,
	}
)

func (x TrainerSpec_ModelType) Enum() *TrainerSpec_ModelType {
	p := new(TrainerSpec_ModelType)
	*p = x
	return p
}

func (x TrainerSpec_ModelType) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (TrainerSpec_ModelType) Descriptor() protoreflect.EnumDescriptor {
	return file_sentencepiece_model_proto_enumTypes[0].Descriptor()
}

func (TrainerSpec_ModelType) Type() protoreflect.EnumType {
	return &file_sentencepiece_model_proto_enumTypes[0]
}

func (x TrainerSpec_ModelType) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Do not use.
func (x *TrainerSpec_ModelType) UnmarshalJSON(b []byte) error {
	num, err := protoimpl.X.UnmarshalJSONEnum(x.Descriptor(), b)
	if err != nil {
		return err
	}
	*x = TrainerSpec_ModelType(num)
	return nil
}

// Deprecated: Use TrainerSpec_ModelType.Descriptor instead.
func (TrainerSpec_ModelType) EnumDescriptor() ([]byte, []int) {
	return file_sentencepiece_model_proto_rawDescGZIP(), []int{0, 0}
}

type ModelProto_SentencePiece_Type int32

const (
	ModelProto_SentencePiece_NORMAL       ModelProto_SentencePiece_Type = 1 // normal symbol
	ModelProto_SentencePiece_UNKNOWN      ModelProto_SentencePiece_Type = 2 // unknown symbol. only <unk> for now.
	ModelProto_SentencePiece_CONTROL      ModelProto_SentencePiece_Type = 3 // control symbols. </s>, <s>, <2ja> etc.
	ModelProto_SentencePiece_USER_DEFINED ModelProto_SentencePiece_Type = 4 // user defined symbols.
	// Typical usage of USER_DEFINED symbol
	// is placeholder.
	ModelProto_SentencePiece_BYTE   ModelProto_SentencePiece_Type = 6 // byte symbols. Used when `byte_fallback` is true.
	ModelProto_SentencePiece_UNUSED ModelProto_SentencePiece_Type = 5 // this piece is not used.
)

// Enum value maps for ModelProto_SentencePiece_Type.
var (
	ModelProto_SentencePiece_Type_name = map[int32]string{
		1: "NORMAL",
		2: "UNKNOWN",
		3: "CONTROL",
		4: "USER_DEFINED",
		6: "BYTE",
		5: "UNUSED",
	}
	ModelProto_SentencePiece_Type_value = map[string]int32{
		"NORMAL":       1,
		"UNKNOWN":      2,
		"CONTROL":      3,
		"USER_DEFINED": 4,
		"BYTE":         6,
		"UNUSED":       5,
	}
)

func (x ModelProto_SentencePiece_Type) Enum() *ModelProto_SentencePiece_Type {
	p := new(ModelProto_SentencePiece_Type)
	*p = x
	return p
}

func (x ModelProto_SentencePiece_Type) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (ModelProto_SentencePiece_Type) Descriptor() protoreflect.EnumDescriptor {
	return file_sentencepiece_model_proto_enumTypes[1].Descriptor()
}

func (ModelProto_SentencePiece_Type) Type() protoreflect.EnumType {
	return &file_sentencepiece_model_proto_enumTypes[1]
}

func (x ModelProto_SentencePiece_Type) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Do not use.
func (x *ModelProto_SentencePiece_Type) UnmarshalJSON(b []byte) error {
	num, err := protoimpl.X.UnmarshalJSONEnum(x.Descriptor(), b)
	if err != nil {
		return err
	}
	*x = ModelProto_SentencePiece_Type(num)
	return nil
}

// Deprecated: Use ModelProto_SentencePiece_Type.Descriptor instead.
func (ModelProto_SentencePiece_Type) EnumDescriptor() ([]byte, []int) {
	return file_sentencepiece_model_proto_rawDescGZIP(), []int{3, 0, 0}
}

// TrainerSpec encodes a various parameters for SentencePiece training.
// Next id: 55
type TrainerSpec struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// /////////////////////////////////////////////////////////////////
	// General parameters
	//
	// Input corpus files.
	//
	//	Trainer accepts the following two formats:
	//	A) Monolingual: plain text, one sentence per line.
	//	B) Bilingual:   TSV, source sentence <tab> target sentence
	//	When bilingual data is passed, shared vocabulary model is built.
	//	Note that the input file must be raw corpus, not a preprocessed corpus.
	//	Trainer only loads the first `input_sentence_size` sentences specified
	//	with this parameter.
	Input []string `protobuf:"bytes,1,rep,name=input" json:"input,omitempty"`
	// Input corpus format:
	// "text": one-sentence-per-line text format (default)
	// "tsv":  sentence <tab> freq
	InputFormat *string `protobuf:"bytes,7,opt,name=input_format,json=inputFormat" json:"input_format,omitempty"`
	// Output model file prefix.
	// <model_prefix>.model and <model_prefix>.vocab are generated.
	ModelPrefix *string                `protobuf:"bytes,2,opt,name=model_prefix,json=modelPrefix" json:"model_prefix,omitempty"`
	ModelType   *TrainerSpec_ModelType `protobuf:"varint,3,opt,name=model_type,json=modelType,enum=sentencepiece.TrainerSpec_ModelType,def=1" json:"model_type,omitempty"`
	// Vocabulary size. 8k is the default size.
	VocabSize *int32 `protobuf:"varint,4,opt,name=vocab_size,json=vocabSize,def=8000" json:"vocab_size,omitempty"`
	// List of the languages this model can accept.
	// Since the model is language-agnostic, this field is used as a reference.
	AcceptLanguage []string `protobuf:"bytes,5,rep,name=accept_language,json=acceptLanguage" json:"accept_language,omitempty"`
	// Size of self-test samples, which are encoded in the model file.
	SelfTestSampleSize *int32 `protobuf:"varint,6,opt,name=self_test_sample_size,json=selfTestSampleSize,def=0" json:"self_test_sample_size,omitempty"`
	// Whether to use DP version of sentencepiece. Use it with TSV input format
	// (requires precomputed word tab counts to work).
	EnableDifferentialPrivacy *bool `protobuf:"varint,50,opt,name=enable_differential_privacy,json=enableDifferentialPrivacy,def=0" json:"enable_differential_privacy,omitempty"`
	// Set these parameters if you need DP version of sentencepiece.
	// std of noise to add.
	DifferentialPrivacyNoiseLevel *float32 `protobuf:"fixed32,51,opt,name=differential_privacy_noise_level,json=differentialPrivacyNoiseLevel,def=0" json:"differential_privacy_noise_level,omitempty"`
	// Clipping threshold to apply after adding noise. All the words with
	// frequency less than this value are dropped.
	DifferentialPrivacyClippingThreshold *uint64 `protobuf:"varint,52,opt,name=differential_privacy_clipping_threshold,json=differentialPrivacyClippingThreshold,def=0" json:"differential_privacy_clipping_threshold,omitempty"`
	// /////////////////////////////////////////////////////////////////
	// Training parameters.
	//
	// Uses characters which cover the corpus with the ratio of `chars_coverage`.
	// This parameter determines the set of basic Alphabet of sentence piece.
	// 1.0 - `chars_coverage` characters are treated as UNK.
	// See also required_chars field.
	CharacterCoverage *float32 `protobuf:"fixed32,10,opt,name=character_coverage,json=characterCoverage,def=0.9995" json:"character_coverage,omitempty"`
	// Maximum size of sentences the trainer loads from `input` parameter.
	// Trainer simply loads the `input` files in sequence.
	// It is better to shuffle the input corpus randomly.
	InputSentenceSize    *uint64 `protobuf:"varint,11,opt,name=input_sentence_size,json=inputSentenceSize,def=0" json:"input_sentence_size,omitempty"`
	ShuffleInputSentence *bool   `protobuf:"varint,19,opt,name=shuffle_input_sentence,json=shuffleInputSentence,def=1" json:"shuffle_input_sentence,omitempty"`
	// Maximum size of sentences to make seed sentence pieces.
	// Extended suffix array is constructed to extract frequent
	// sub-strings from the corpus. This uses 20N working space,
	// where N is the size of corpus.
	//
	// Deprecated: Marked as deprecated in sentencepiece_model.proto.
	MiningSentenceSize *int32 `protobuf:"varint,12,opt,name=mining_sentence_size,json=miningSentenceSize" json:"mining_sentence_size,omitempty"`
	// Maximum size of sentences to train sentence pieces.
	//
	// Deprecated: Marked as deprecated in sentencepiece_model.proto.
	TrainingSentenceSize *int32 `protobuf:"varint,13,opt,name=training_sentence_size,json=trainingSentenceSize" json:"training_sentence_size,omitempty"`
	// The size of seed sentencepieces.
	// `seed_sentencepiece_size` must be larger than `vocab_size`.
	SeedSentencepieceSize *int32 `protobuf:"varint,14,opt,name=seed_sentencepiece_size,json=seedSentencepieceSize,def=1000000" json:"seed_sentencepiece_size,omitempty"`
	// In every EM sub-iterations, keeps top
	// `shrinking_factor` * `current sentencepieces size` with respect to
	// the loss of the sentence piece. This value should be smaller than 1.0.
	ShrinkingFactor *float32 `protobuf:"fixed32,15,opt,name=shrinking_factor,json=shrinkingFactor,def=0.75" json:"shrinking_factor,omitempty"`
	// The maximum sentence length in byte. The sentences with the length
	// larger than `max_sentence_length` is simply ignored.
	// Longer input tends to bring the following risks:
	//   - Overflow during EM training (unigram language model only)
	//   - Performance drop because of O(n log n) cost in BPE.
	MaxSentenceLength *int32 `protobuf:"varint,18,opt,name=max_sentence_length,json=maxSentenceLength,def=4192" json:"max_sentence_length,omitempty"`
	// Number of threads in the training.
	NumThreads *int32 `protobuf:"varint,16,opt,name=num_threads,json=numThreads,def=16" json:"num_threads,omitempty"`
	// Number of EM sub iterations.
	NumSubIterations *int32 `protobuf:"varint,17,opt,name=num_sub_iterations,json=numSubIterations,def=2" json:"num_sub_iterations,omitempty"`
	// /////////////////////////////////////////////////////////////////
	// SentencePiece parameters which control the shapes of sentence piece.
	//
	// Maximum length of sentencepiece.
	MaxSentencepieceLength *int32 `protobuf:"varint,20,opt,name=max_sentencepiece_length,json=maxSentencepieceLength,def=16" json:"max_sentencepiece_length,omitempty"`
	// Uses Unicode script to split sentence pieces.
	// When `split_by_unicode_script` is true, we do not allow sentence piece to
	// include multiple Unicode scripts, e.g. "F1" is not a valid piece.
	// Exception: CJ characters (Hiragana/Katakana/Han) are all handled
	// as one script type, since Japanese word can consist of multiple scripts.
	// This exception is always applied regardless of the accept-language
	// parameter.
	SplitByUnicodeScript *bool `protobuf:"varint,21,opt,name=split_by_unicode_script,json=splitByUnicodeScript,def=1" json:"split_by_unicode_script,omitempty"`
	// When `split_by_number` is true, put a boundary between number and
	// non-number transition. If we want to treat "F1" is one token, set this flag
	// to be false.
	SplitByNumber *bool `protobuf:"varint,23,opt,name=split_by_number,json=splitByNumber,def=1" json:"split_by_number,omitempty"`
	// Use a white space to split sentence pieces.
	// When `split_by_whitespace` is false, we may have the piece containing
	// a white space in the middle. e.g., "in_the".
	SplitByWhitespace *bool `protobuf:"varint,22,opt,name=split_by_whitespace,json=splitByWhitespace,def=1" json:"split_by_whitespace,omitempty"`
	// Adds whitespace symbol (_) as a suffix instead of prefix. e.g., _hello =>
	// hello_. When `treat_whitespace_as_suffix` is true,
	// NormalizerSpec::add_dummy_prefix will add the dummy whitespace to the end
	// of sentence.
	TreatWhitespaceAsSuffix *bool `protobuf:"varint,24,opt,name=treat_whitespace_as_suffix,json=treatWhitespaceAsSuffix,def=0" json:"treat_whitespace_as_suffix,omitempty"`
	// Allows pieces that only contain whitespaces instead of appearing only as
	// prefix or suffix of other pieces.
	AllowWhitespaceOnlyPieces *bool `protobuf:"varint,26,opt,name=allow_whitespace_only_pieces,json=allowWhitespaceOnlyPieces,def=0" json:"allow_whitespace_only_pieces,omitempty"`
	// Split all digits (0-9) into separate pieces.
	SplitDigits *bool `protobuf:"varint,25,opt,name=split_digits,json=splitDigits,def=0" json:"split_digits,omitempty"`
	// Defines the pre-tokenization delimiter.
	// When specified, no pieces crossing this delimiter is not included
	// in the vocab. Then the delimiter string is virtually ignored
	// during the training. This field can allows constraints on the vocabulary
	// selection. Note that this field is available on unigram mode.
	PretokenizationDelimiter *string `protobuf:"bytes,53,opt,name=pretokenization_delimiter,json=pretokenizationDelimiter,def=" json:"pretokenization_delimiter,omitempty"`
	// /////////////////////////////////////////////////////////////////
	// Vocabulary management
	//
	// Defines control symbols used as an indicator to
	// change the behavior of the decoder. <s> and </s> are pre-defined.
	// We can use this field to encode various meta information,
	// including language indicator in multilingual model.
	// These symbols are not visible to users, but visible to
	// the decoder. Note that when the input sentence contains control symbols,
	// they are not treated as one token, but segmented into normal pieces.
	// Control symbols must be inserted independently from the segmentation.
	ControlSymbols []string `protobuf:"bytes,30,rep,name=control_symbols,json=controlSymbols" json:"control_symbols,omitempty"`
	// Defines user defined symbols.
	// These symbols are added with extremely high score
	// so they are always treated as one unique symbol in any context.
	// Typical usage of user_defined_symbols is placeholder for named entities.
	UserDefinedSymbols []string `protobuf:"bytes,31,rep,name=user_defined_symbols,json=userDefinedSymbols" json:"user_defined_symbols,omitempty"`
	// Defines required characters. Each UTF8 character in this string is included
	// in the character set regardless of character_coverage value. Unlike
	// user_defined_symbols, these characters have scores based on the frequency
	// on input sentences, and the model can form subwords using characters
	// in this field.
	RequiredChars *string `protobuf:"bytes,36,opt,name=required_chars,json=requiredChars" json:"required_chars,omitempty"`
	// Decomposes unknown pieces into UTF-8 bytes.
	ByteFallback *bool `protobuf:"varint,35,opt,name=byte_fallback,json=byteFallback,def=0" json:"byte_fallback,omitempty"`
	// When creating the vocabulary file, defines whether or not to additionally
	// output the score for each piece.
	VocabularyOutputPieceScore *bool `protobuf:"varint,32,opt,name=vocabulary_output_piece_score,json=vocabularyOutputPieceScore,def=1" json:"vocabulary_output_piece_score,omitempty"`
	// `vocab_size` is treated as hard limit. Crash if
	// the model can not produce the vocab of size `vocab_size`,
	// When `hard_vocab_limit` is false, vocab_size is treated
	// as soft limit. Note that when model_type=char,
	// always assumes hard_vocab_limit = false.
	HardVocabLimit *bool `protobuf:"varint,33,opt,name=hard_vocab_limit,json=hardVocabLimit,def=1" json:"hard_vocab_limit,omitempty"`
	// use all symbols for vocab extraction. This flag is valid
	// if model type is either CHAR or WORD
	UseAllVocab *bool `protobuf:"varint,34,opt,name=use_all_vocab,json=useAllVocab,def=0" json:"use_all_vocab,omitempty"`
	// /////////////////////////////////////////////////////////////////
	// Reserved special meta tokens.
	// * -1 is not used.
	// * unk_id must not be -1.
	// Id must starts with 0 and be contigous.
	UnkId    *int32  `protobuf:"varint,40,opt,name=unk_id,json=unkId,def=0" json:"unk_id,omitempty"`  // <unk>
	BosId    *int32  `protobuf:"varint,41,opt,name=bos_id,json=bosId,def=1" json:"bos_id,omitempty"`  // <s>
	EosId    *int32  `protobuf:"varint,42,opt,name=eos_id,json=eosId,def=2" json:"eos_id,omitempty"`  // </s>
	PadId    *int32  `protobuf:"varint,43,opt,name=pad_id,json=padId,def=-1" json:"pad_id,omitempty"` // <pad> (padding)
	UnkPiece *string `protobuf:"bytes,45,opt,name=unk_piece,json=unkPiece,def=<unk>" json:"unk_piece,omitempty"`
	BosPiece *string `protobuf:"bytes,46,opt,name=bos_piece,json=bosPiece,def=<s>" json:"bos_piece,omitempty"`
	EosPiece *string `protobuf:"bytes,47,opt,name=eos_piece,json=eosPiece,def=</s>" json:"eos_piece,omitempty"`
	PadPiece *string `protobuf:"bytes,48,opt,name=pad_piece,json=padPiece,def=<pad>" json:"pad_piece,omitempty"`
	// Encodes <unk> into U+2047 (DOUBLE QUESTION MARK),
	// since this character can be useful both for user and
	// developer. We can easily figure out that <unk> is emitted.
	UnkSurface *string `protobuf:"bytes,44,opt,name=unk_surface,json=unkSurface,def= ⁇ " json:"unk_surface,omitempty"`
	// Increase bit depth to allow unigram model training on large
	// (>10M sentences) corpora. A Side-effect of enabling this flag
	// is increased memory usage.
	TrainExtremelyLargeCorpus *bool `protobuf:"varint,49,opt,name=train_extremely_large_corpus,json=trainExtremelyLargeCorpus,def=0" json:"train_extremely_large_corpus,omitempty"`
	// Path to a seed sentencepieces file, with one tab-separated
	// seed sentencepiece <tab> frequency per line.
	SeedSentencepiecesFile *string `protobuf:"bytes,54,opt,name=seed_sentencepieces_file,json=seedSentencepiecesFile,def=" json:"seed_sentencepieces_file,omitempty"`
	extensionFields        protoimpl.ExtensionFields
	unknownFields          protoimpl.UnknownFields
	sizeCache              protoimpl.SizeCache
}

// Default values for TrainerSpec fields.
const (
	Default_TrainerSpec_ModelType                            = TrainerSpec_UNIGRAM
	Default_TrainerSpec_VocabSize                            = int32(8000)
	Default_TrainerSpec_SelfTestSampleSize                   = int32(0)
	Default_TrainerSpec_EnableDifferentialPrivacy            = bool(false)
	Default_TrainerSpec_DifferentialPrivacyNoiseLevel        = float32(0)
	Default_TrainerSpec_DifferentialPrivacyClippingThreshold = uint64(0)
	Default_TrainerSpec_CharacterCoverage                    = float32(0.9994999766349792)
	Default_TrainerSpec_InputSentenceSize                    = uint64(0)
	Default_TrainerSpec_ShuffleInputSentence                 = bool(true)
	Default_TrainerSpec_SeedSentencepieceSize                = int32(1000000)
	Default_TrainerSpec_ShrinkingFactor                      = float32(0.75)
	Default_TrainerSpec_MaxSentenceLength                    = int32(4192)
	Default_TrainerSpec_NumThreads                           = int32(16)
	Default_TrainerSpec_NumSubIterations                     = int32(2)
	Default_TrainerSpec_MaxSentencepieceLength               = int32(16)
	Default_TrainerSpec_SplitByUnicodeScript                 = bool(true)
	Default_TrainerSpec_SplitByNumber                        = bool(true)
	Default_TrainerSpec_SplitByWhitespace                    = bool(true)
	Default_TrainerSpec_TreatWhitespaceAsSuffix              = bool(false)
	Default_TrainerSpec_AllowWhitespaceOnlyPieces            = bool(false)
	Default_TrainerSpec_SplitDigits                          = bool(false)
	Default_TrainerSpec_PretokenizationDelimiter             = string("")
	Default_TrainerSpec_ByteFallback                         = bool(false)
	Default_TrainerSpec_VocabularyOutputPieceScore           = bool(true)
	Default_TrainerSpec_HardVocabLimit                       = bool(true)
	Default_TrainerSpec_UseAllVocab                          = bool(false)
	Default_TrainerSpec_UnkId                                = int32(0)
	Default_TrainerSpec_BosId                                = int32(1)
	Default_TrainerSpec_EosId                                = int32(2)
	Default_TrainerSpec_PadId                                = int32(-1)
	Default_TrainerSpec_UnkPiece                             = string("<unk>")
	Default_TrainerSpec_BosPiece                             = string("<s>")
	Default_TrainerSpec_EosPiece                             = string("</s>")
	Default_TrainerSpec_PadPiece                             = string("<pad>")
	Default_TrainerSpec_UnkSurface                           = string(" ⁇ ")
	Default_TrainerSpec_TrainExtremelyLargeCorpus            = bool(false)
	Default_TrainerSpec_SeedSentencepiecesFile               = string("")
)

func (x *TrainerSpec) Reset() {
	*x = TrainerSpec{}
	mi := &file_sentencepiece_model_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *TrainerSpec) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*TrainerSpec) ProtoMessage() {}

func (x *TrainerSpec) ProtoReflect() protoreflect.Message {
	mi := &file_sentencepiece_model_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use TrainerSpec.ProtoReflect.Descriptor instead.
func (*TrainerSpec) Descriptor() ([]byte, []int) {
	return file_sentencepiece_model_proto_rawDescGZIP(), []int{0}
}

func (x *TrainerSpec) GetInput() []string {
	if x != nil {
		return x.Input
	}
	return nil
}

func (x *TrainerSpec) GetInputFormat() string {
	if x != nil && x.InputFormat != nil {
		return *x.InputFormat
	}
	return ""
}

func (x *TrainerSpec) GetModelPrefix() string {
	if x != nil && x.ModelPrefix != nil {
		return *x.ModelPrefix
	}
	return ""
}

func (x *TrainerSpec) GetModelType() TrainerSpec_ModelType {
	if x != nil && x.ModelType != nil {
		return *x.ModelType
	}
	return Default_TrainerSpec_ModelType
}

func (x *TrainerSpec) GetVocabSize() int32 {
	if x != nil && x.VocabSize != nil {
		return *x.VocabSize
	}
	return Default_TrainerSpec_VocabSize
}

func (x *TrainerSpec) GetAcceptLanguage() []string {
	if x != nil {
		return x.AcceptLanguage
	}
	return nil
}

func (x *TrainerSpec) GetSelfTestSampleSize() int32 {
	if x != nil && x.SelfTestSampleSize != nil {
		return *x.SelfTestSampleSize
	}
	return Default_TrainerSpec_SelfTestSampleSize
}

func (x *TrainerSpec) GetEnableDifferentialPrivacy() bool {
	if x != nil && x.EnableDifferentialPrivacy != nil {
		return *x.EnableDifferentialPrivacy
	}
	return Default_TrainerSpec_EnableDifferentialPrivacy
}

func (x *TrainerSpec) GetDifferentialPrivacyNoiseLevel() float32 {
	if x != nil && x.DifferentialPrivacyNoiseLevel != nil {
		return *x.DifferentialPrivacyNoiseLevel
	}
	return Default_TrainerSpec_DifferentialPrivacyNoiseLevel
}

func (x *TrainerSpec) GetDifferentialPrivacyClippingThreshold() uint64 {
	if x != nil && x.DifferentialPrivacyClippingThreshold != nil {
		return *x.DifferentialPrivacyClippingThreshold
	}
	return Default_TrainerSpec_DifferentialPrivacyClippingThreshold
}

func (x *TrainerSpec) GetCharacterCoverage() float32 {
	if x != nil && x.CharacterCoverage != nil {
		return *x.CharacterCoverage
	}
	return Default_TrainerSpec_CharacterCoverage
}

func (x *TrainerSpec) GetInputSentenceSize() uint64 {
	if x != nil && x.InputSentenceSize != nil {
		return *x.InputSentenceSize
	}
	return Default_TrainerSpec_InputSentenceSize
}

func (x *TrainerSpec) GetShuffleInputSentence() bool {
	if x != nil && x.ShuffleInputSentence != nil {
		return *x.ShuffleInputSentence
	}
	return Default_TrainerSpec_ShuffleInputSentence
}

// Deprecated: Marked as deprecated in sentencepiece_model.proto.
func (x *TrainerSpec) GetMiningSentenceSize() int32 {
	if x != nil && x.MiningSentenceSize != nil {
		return *x.MiningSentenceSize
	}
	return 0
}

// Deprecated: Marked as deprecated in sentencepiece_model.proto.
func (x *TrainerSpec) GetTrainingSentenceSize() int32 {
	if x != nil && x.TrainingSentenceSize != nil {
		return *x.TrainingSentenceSize
	}
	return 0
}

func (x *TrainerSpec) GetSeedSentencepieceSize() int32 {
	if x != nil && x.SeedSentencepieceSize != nil {
		return *x.SeedSentencepieceSize
	}
	return Default_TrainerSpec_SeedSentencepieceSize
}

func (x *TrainerSpec) GetShrinkingFactor() float32 {
	if x != nil && x.ShrinkingFactor != nil {
		return *x.ShrinkingFactor
	}
	return Default_TrainerSpec_ShrinkingFactor
}

func (x *TrainerSpec) GetMaxSentenceLength() int32 {
	if x != nil && x.MaxSentenceLength != nil {
		return *x.MaxSentenceLength
	}
	return Default_TrainerSpec_MaxSentenceLength
}

func (x *TrainerSpec) GetNumThreads() int32 {
	if x != nil && x.NumThreads != nil {
		return *x.NumThreads
	}
	return Default_TrainerSpec_NumThreads
}

func (x *TrainerSpec) GetNumSubIterations() int32 {
	if x != nil && x.NumSubIterations != nil {
		return *x.NumSubIterations
	}
	return Default_TrainerSpec_NumSubIterations
}

func (x *TrainerSpec) GetMaxSentencepieceLength() int32 {
	if x != nil && x.MaxSentencepieceLength != nil {
		return *x.MaxSentencepieceLength
	}
	return Default_TrainerSpec_MaxSentencepieceLength
}

func (x *TrainerSpec) GetSplitByUnicodeScript() bool {
	if x != nil && x.SplitByUnicodeScript != nil {
		return *x.SplitByUnicodeScript
	}
	return Default_TrainerSpec_SplitByUnicodeScript
}

func (x *TrainerSpec) GetSplitByNumber() bool {
	if x != nil && x.SplitByNumber != nil {
		return *x.SplitByNumber
	}
	return Default_TrainerSpec_SplitByNumber
}

func (x *TrainerSpec) GetSplitByWhitespace() bool {
	if x != nil && x.SplitByWhitespace != nil {
		return *x.SplitByWhitespace
	}
	return Default_TrainerSpec_SplitByWhitespace
}

func (x *TrainerSpec) GetTreatWhitespaceAsSuffix() bool {
	if x != nil && x.TreatWhitespaceAsSuffix != nil {
		return *x.TreatWhitespaceAsSuffix
	}
	return Default_TrainerSpec_TreatWhitespaceAsSuffix
}

func (x *TrainerSpec) GetAllowWhitespaceOnlyPieces() bool {
	if x != nil && x.AllowWhitespaceOnlyPieces != nil {
		return *x.AllowWhitespaceOnlyPieces
	}
	return Default_TrainerSpec_AllowWhitespaceOnlyPieces
}

func (x *TrainerSpec) GetSplitDigits() bool {
	if x != nil && x.SplitDigits != nil {
		return *x.SplitDigits
	}
	return Default_TrainerSpec_SplitDigits
}

func (x *TrainerSpec) GetPretokenizationDelimiter() string {
	if x != nil && x.PretokenizationDelimiter != nil {
		return *x.PretokenizationDelimiter
	}
	return Default_TrainerSpec_PretokenizationDelimiter
}

func (x *TrainerSpec) GetControlSymbols() []string {
	if x != nil {
		return x.ControlSymbols
	}
	return nil
}

func (x *TrainerSpec) GetUserDefinedSymbols() []string {
	if x != nil {
		return x.UserDefinedSymbols
	}
	return nil
}

func (x *TrainerSpec) GetRequiredChars() string {
	if x != nil && x.RequiredChars != nil {
		return *x.RequiredChars
	}
	return ""
}

func (x *TrainerSpec) GetByteFallback() bool {
	if x != nil && x.ByteFallback != nil {
		return *x.ByteFallback
	}
	return Default_TrainerSpec_ByteFallback
}

func (x *TrainerSpec) GetVocabularyOutputPieceScore() bool {
	if x != nil && x.VocabularyOutputPieceScore != nil {
		return *x.VocabularyOutputPieceScore
	}
	return Default_TrainerSpec_VocabularyOutputPieceScore
}

func (x *TrainerSpec) GetHardVocabLimit() bool {
	if x != nil && x.HardVocabLimit != nil {
		return *x.HardVocabLimit
	}
	return Default_TrainerSpec_HardVocabLimit
}

func (x *TrainerSpec) GetUseAllVocab() bool {
	if x != nil && x.UseAllVocab != nil {
		return *x.UseAllVocab
	}
	return Default_TrainerSpec_UseAllVocab
}

func (x *TrainerSpec) GetUnkId() int32 {
	if x != nil && x.UnkId != nil {
		return *x.UnkId
	}
	return Default_TrainerSpec_UnkId
}

func (x *TrainerSpec) GetBosId() int32 {
	if x != nil && x.BosId != nil {
		return *x.BosId
	}
	return Default_TrainerSpec_BosId
}

func (x *TrainerSpec) GetEosId() int32 {
	if x != nil && x.EosId != nil {
		return *x.EosId
	}
	return Default_TrainerSpec_EosId
}

func (x *TrainerSpec) GetPadId() int32 {
	if x != nil && x.PadId != nil {
		return *x.PadId
	}
	return Default_TrainerSpec_PadId
}

func (x *TrainerSpec) GetUnkPiece() string {
	if x != nil && x.UnkPiece != nil {
		return *x.UnkPiece
	}
	return Default_TrainerSpec_UnkPiece
}

func (x *TrainerSpec) GetBosPiece() string {
	if x != nil && x.BosPiece != nil {
		return *x.BosPiece
	}
	return Default_TrainerSpec_BosPiece
}

func (x *TrainerSpec) GetEosPiece() string {
	if x != nil && x.EosPiece != nil {
		return *x.EosPiece
	}
	return Default_TrainerSpec_EosPiece
}

func (x *TrainerSpec) GetPadPiece() string {
	if x != nil && x.PadPiece != nil {
		return *x.PadPiece
	}
	return Default_TrainerSpec_PadPiece
}

func (x *TrainerSpec) GetUnkSurface() string {
	if x != nil && x.UnkSurface != nil {
		return *x.UnkSurface
	}
	return Default_TrainerSpec_UnkSurface
}

func (x *TrainerSpec) GetTrainExtremelyLargeCorpus() bool {
	if x != nil && x.TrainExtremelyLargeCorpus != nil {
		return *x.TrainExtremelyLargeCorpus
	}
	return Default_TrainerSpec_TrainExtremelyLargeCorpus
}

func (x *TrainerSpec) GetSeedSentencepiecesFile() string {
	if x != nil && x.SeedSentencepiecesFile != nil {
		return *x.SeedSentencepiecesFile
	}
	return Default_TrainerSpec_SeedSentencepiecesFile
}

// NormalizerSpec encodes a various parameters for string normalizaiton
type NormalizerSpec struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// name of normalization rule.
	Name *string `protobuf:"bytes,1,opt,name=name" json:"name,omitempty"`
	// Pre-compiled normalization rule created by
	// Builder::GetPrecompiledCharsMap() or Builder::CompileCharsMap() method.
	// Usually this field is set by Builder::GetNormalizerSpec() method.
	PrecompiledCharsmap []byte `protobuf:"bytes,2,opt,name=precompiled_charsmap,json=precompiledCharsmap" json:"precompiled_charsmap,omitempty"`
	// Adds dummy whitespace at the beginning of text in order to
	// treat "world" in "world" and "hello world" in the same way.
	AddDummyPrefix *bool `protobuf:"varint,3,opt,name=add_dummy_prefix,json=addDummyPrefix,def=1" json:"add_dummy_prefix,omitempty"`
	// Removes leading, trailing, and duplicate internal whitespace.
	RemoveExtraWhitespaces *bool `protobuf:"varint,4,opt,name=remove_extra_whitespaces,json=removeExtraWhitespaces,def=1" json:"remove_extra_whitespaces,omitempty"`
	// Replaces whitespace with meta symbol.
	// This field must be true to train sentence piece model.
	EscapeWhitespaces *bool `protobuf:"varint,5,opt,name=escape_whitespaces,json=escapeWhitespaces,def=1" json:"escape_whitespaces,omitempty"`
	// Custom normalization rule file in TSV format.
	// https://github.com/google/sentencepiece/blob/master/doc/normalization.md
	// This field is only used in SentencePieceTrainer::Train() method, which
	// compiles the rule into the binary rule stored in `precompiled_charsmap`.
	NormalizationRuleTsv *string `protobuf:"bytes,6,opt,name=normalization_rule_tsv,json=normalizationRuleTsv" json:"normalization_rule_tsv,omitempty"`
	extensionFields      protoimpl.ExtensionFields
	unknownFields        protoimpl.UnknownFields
	sizeCache            protoimpl.SizeCache
}

// Default values for NormalizerSpec fields.
const (
	Default_NormalizerSpec_AddDummyPrefix         = bool(true)
	Default_NormalizerSpec_RemoveExtraWhitespaces = bool(true)
	Default_NormalizerSpec_EscapeWhitespaces      = bool(true)
)

func (x *NormalizerSpec) Reset() {
	*x = NormalizerSpec{}
	mi := &file_sentencepiece_model_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *NormalizerSpec) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*NormalizerSpec) ProtoMessage() {}

func (x *NormalizerSpec) ProtoReflect() protoreflect.Message {
	mi := &file_sentencepiece_model_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use NormalizerSpec.ProtoReflect.Descriptor instead.
func (*NormalizerSpec) Descriptor() ([]byte, []int) {
	return file_sentencepiece_model_proto_rawDescGZIP(), []int{1}
}

func (x *NormalizerSpec) GetName() string {
	if x != nil && x.Name != nil {
		return *x.Name
	}
	return ""
}

func (x *NormalizerSpec) GetPrecompiledCharsmap() []byte {
	if x != nil {
		return x.PrecompiledCharsmap
	}
	return nil
}

func (x *NormalizerSpec) GetAddDummyPrefix() bool {
	if x != nil && x.AddDummyPrefix != nil {
		return *x.AddDummyPrefix
	}
	return Default_NormalizerSpec_AddDummyPrefix
}

func (x *NormalizerSpec) GetRemoveExtraWhitespaces() bool {
	if x != nil && x.RemoveExtraWhitespaces != nil {
		return *x.RemoveExtraWhitespaces
	}
	return Default_NormalizerSpec_RemoveExtraWhitespaces
}

func (x *NormalizerSpec) GetEscapeWhitespaces() bool {
	if x != nil && x.EscapeWhitespaces != nil {
		return *x.EscapeWhitespaces
	}
	return Default_NormalizerSpec_EscapeWhitespaces
}

func (x *NormalizerSpec) GetNormalizationRuleTsv() string {
	if x != nil && x.NormalizationRuleTsv != nil {
		return *x.NormalizationRuleTsv
	}
	return ""
}

// Proto to store samples for self-testing.
type SelfTestData struct {
	state           protoimpl.MessageState `protogen:"open.v1"`
	Samples         []*SelfTestData_Sample `protobuf:"bytes,1,rep,name=samples" json:"samples,omitempty"`
	extensionFields protoimpl.ExtensionFields
	unknownFields   protoimpl.UnknownFields
	sizeCache       protoimpl.SizeCache
}

func (x *SelfTestData) Reset() {
	*x = SelfTestData{}
	mi := &file_sentencepiece_model_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SelfTestData) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SelfTestData) ProtoMessage() {}

func (x *SelfTestData) ProtoReflect() protoreflect.Message {
	mi := &file_sentencepiece_model_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SelfTestData.ProtoReflect.Descriptor instead.
func (*SelfTestData) Descriptor() ([]byte, []int) {
	return file_sentencepiece_model_proto_rawDescGZIP(), []int{2}
}

func (x *SelfTestData) GetSamples() []*SelfTestData_Sample {
	if x != nil {
		return x.Samples
	}
	return nil
}

// ModelProto stores model parameters.
// SentencePieceProcessor is supposed to be self-contained.
// All settings/parameters which may change the behavior must be encoded
// in ModelProto.
type ModelProto struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Sentence pieces with scores.
	Pieces []*ModelProto_SentencePiece `protobuf:"bytes,1,rep,name=pieces" json:"pieces,omitempty"`
	// Spec used to generate this model file.
	TrainerSpec *TrainerSpec `protobuf:"bytes,2,opt,name=trainer_spec,json=trainerSpec" json:"trainer_spec,omitempty"`
	// Spec for text normalization.
	NormalizerSpec *NormalizerSpec `protobuf:"bytes,3,opt,name=normalizer_spec,json=normalizerSpec" json:"normalizer_spec,omitempty"`
	// Stores sample input and its expected segmentation to verify the model.
	SelfTestData *SelfTestData `protobuf:"bytes,4,opt,name=self_test_data,json=selfTestData" json:"self_test_data,omitempty"`
	// Spec for text de-normalization.
	DenormalizerSpec *NormalizerSpec `protobuf:"bytes,5,opt,name=denormalizer_spec,json=denormalizerSpec" json:"denormalizer_spec,omitempty"`
	extensionFields  protoimpl.ExtensionFields
	unknownFields    protoimpl.UnknownFields
	sizeCache        protoimpl.SizeCache
}

func (x *ModelProto) Reset() {
	*x = ModelProto{}
	mi := &file_sentencepiece_model_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ModelProto) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ModelProto) ProtoMessage() {}

func (x *ModelProto) ProtoReflect() protoreflect.Message {
	mi := &file_sentencepiece_model_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ModelProto.ProtoReflect.Descriptor instead.
func (*ModelProto) Descriptor() ([]byte, []int) {
	return file_sentencepiece_model_proto_rawDescGZIP(), []int{3}
}

func (x *ModelProto) GetPieces() []*ModelProto_SentencePiece {
	if x != nil {
		return x.Pieces
	}
	return nil
}

func (x *ModelProto) GetTrainerSpec() *TrainerSpec {
	if x != nil {
		return x.TrainerSpec
	}
	return nil
}

func (x *ModelProto) GetNormalizerSpec() *NormalizerSpec {
	if x != nil {
		return x.NormalizerSpec
	}
	return nil
}

func (x *ModelProto) GetSelfTestData() *SelfTestData {
	if x != nil {
		return x.SelfTestData
	}
	return nil
}

func (x *ModelProto) GetDenormalizerSpec() *NormalizerSpec {
	if x != nil {
		return x.DenormalizerSpec
	}
	return nil
}

type SelfTestData_Sample struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Input         *string                `protobuf:"bytes,1,opt,name=input" json:"input,omitempty"`
	Expected      *string                `protobuf:"bytes,2,opt,name=expected" json:"expected,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SelfTestData_Sample) Reset() {
	*x = SelfTestData_Sample{}
	mi := &file_sentencepiece_model_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SelfTestData_Sample) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SelfTestData_Sample) ProtoMessage() {}

func (x *SelfTestData_Sample) ProtoReflect() protoreflect.Message {
	mi := &file_sentencepiece_model_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SelfTestData_Sample.ProtoReflect.Descriptor instead.
func (*SelfTestData_Sample) Descriptor() ([]byte, []int) {
	return file_sentencepiece_model_proto_rawDescGZIP(), []int{2, 0}
}

func (x *SelfTestData_Sample) GetInput() string {
	if x != nil && x.Input != nil {
		return *x.Input
	}
	return ""
}

func (x *SelfTestData_Sample) GetExpected() string {
	if x != nil && x.Expected != nil {
		return *x.Expected
	}
	return ""
}

type ModelProto_SentencePiece struct {
	state           protoimpl.MessageState         `protogen:"open.v1"`
	Piece           *string                        `protobuf:"bytes,1,opt,name=piece" json:"piece,omitempty"` // piece must not be empty.
	Score           *float32                       `protobuf:"fixed32,2,opt,name=score" json:"score,omitempty"`
	Type            *ModelProto_SentencePiece_Type `protobuf:"varint,3,opt,name=type,enum=sentencepiece.ModelProto_SentencePiece_Type,def=1" json:"type,omitempty"`
	extensionFields protoimpl.ExtensionFields
	unknownFields   protoimpl.UnknownFields
	sizeCache       protoimpl.SizeCache
}

// Default values for ModelProto_SentencePiece fields.
const (
	Default_ModelProto_SentencePiece_Type = ModelProto_SentencePiece_NORMAL
)

func (x *ModelProto_SentencePiece) Reset() {
	*x = ModelProto_SentencePiece{}
	mi := &file_sentencepiece_model_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ModelProto_SentencePiece) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ModelProto_SentencePiece) ProtoMessage() {}

func (x *ModelProto_SentencePiece) ProtoReflect() protoreflect.Message {
	mi := &file_sentencepiece_model_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ModelProto_SentencePiece.ProtoReflect.Descriptor instead.
func (*ModelProto_SentencePiece) Descriptor() ([]byte, []int) {
	return file_sentencepiece_model_proto_rawDescGZIP(), []int{3, 0}
}

func (x *ModelProto_SentencePiece) GetPiece() string {
	if x != nil && x.Piece != nil {
		return *x.Piece
	}
	return ""
}

func (x *ModelProto_SentencePiece) GetScore() float32 {
	if x != nil && x.Score != nil {
		return *x.Score
	}
	return 0
}

func (x *ModelProto_SentencePiece) GetType() ModelProto_SentencePiece_Type {
	if x != nil && x.Type != nil {
		return *x.Type
	}
	return Default_ModelProto_SentencePiece_Type
}

var File_sentencepiece_model_proto protoreflect.FileDescriptor

const file_sentencepiece_model_proto_rawDesc = "" +
	"\n" +
	"\x19sentencepiece_model.proto\x12\rsentencepiece\"\xc6\x12\n" +
	"\vTrainerSpec\x12\x14\n" +
	"\x05input\x18\x01 \x03(\tR\x05input\x12!\n" +
	"\finput_format\x18\a \x01(\tR\vinputFormat\x12!\n" +
	"\fmodel_prefix\x18\x02 \x01(\tR\vmodelPrefix\x12L\n" +
	"\n" +
	"model_type\x18\x03 \x01(\x0e2$.sentencepiece.TrainerSpec.ModelType:\aUNIGRAMR\tmodelType\x12#\n" +
	"\n" +
	"vocab_size\x18\x04 \x01(\x05:\x048000R\tvocabSize\x12'\n" +
	"\x0faccept_language\x18\x05 \x03(\tR\x0eacceptLanguage\x124\n" +
	"\x15self_test_sample_size\x18\x06 \x01(\x05:\x010R\x12selfTestSampleSize\x12E\n" +
	"\x1benable_differential_privacy\x182 \x01(\b:\x05falseR\x19enableDifferentialPrivacy\x12J\n" +
	" differential_privacy_noise_level\x183 \x01(\x02:\x010R\x1ddifferentialPrivacyNoiseLevel\x12X\n" +
	"'differential_privacy_clipping_threshold\x184 \x01(\x04:\x010R$differentialPrivacyClippingThreshold\x125\n" +
	"\x12character_coverage\x18\n" +
	" \x01(\x02:\x060.9995R\x11characterCoverage\x121\n" +
	"\x13input_sentence_size\x18\v \x01(\x04:\x010R\x11inputSentenceSize\x12:\n" +
	"\x16shuffle_input_sentence\x18\x13 \x01(\b:\x04trueR\x14shuffleInputSentence\x124\n" +
	"\x14mining_sentence_size\x18\f \x01(\x05B\x02\x18\x01R\x12miningSentenceSize\x128\n" +
	"\x16training_sentence_size\x18\r \x01(\x05B\x02\x18\x01R\x14trainingSentenceSize\x12?\n" +
	"\x17seed_sentencepiece_size\x18\x0e \x01(\x05:\a1000000R\x15seedSentencepieceSize\x12/\n" +
	"\x10shrinking_factor\x18\x0f \x01(\x02:\x040.75R\x0fshrinkingFactor\x124\n" +
	"\x13max_sentence_length\x18\x12 \x01(\x05:\x044192R\x11maxSentenceLength\x12#\n" +
	"\vnum_threads\x18\x10 \x01(\x05:\x0216R\n" +
	"numThreads\x12/\n" +
	"\x12num_sub_iterations\x18\x11 \x01(\x05:\x012R\x10numSubIterations\x12<\n" +
	"\x18max_sentencepiece_length\x18\x14 \x01(\x05:\x0216R\x16maxSentencepieceLength\x12;\n" +
	"\x17split_by_unicode_script\x18\x15 \x01(\b:\x04trueR\x14splitByUnicodeScript\x12,\n" +
	"\x0fsplit_by_number\x18\x17 \x01(\b:\x04trueR\rsplitByNumber\x124\n" +
	"\x13split_by_whitespace\x18\x16 \x01(\b:\x04trueR\x11splitByWhitespace\x12B\n" +
	"\x1atreat_whitespace_as_suffix\x18\x18 \x01(\b:\x05falseR\x17treatWhitespaceAsSuffix\x12F\n" +
	"\x1callow_whitespace_only_pieces\x18\x1a \x01(\b:\x05falseR\x19allowWhitespaceOnlyPieces\x12(\n" +
	"\fsplit_digits\x18\x19 \x01(\b:\x05falseR\vsplitDigits\x12=\n" +
	"\x19pretokenization_delimiter\x185 \x01(\t:\x00R\x18pretokenizationDelimiter\x12'\n" +
	"\x0fcontrol_symbols\x18\x1e \x03(\tR\x0econtrolSymbols\x120\n" +
	"\x14user_defined_symbols\x18\x1f \x03(\tR\x12userDefinedSymbols\x12%\n" +
	"\x0erequired_chars\x18$ \x01(\tR\rrequiredChars\x12*\n" +
	"\rbyte_fallback\x18# \x01(\b:\x05falseR\fbyteFallback\x12G\n" +
	"\x1dvocabulary_output_piece_score\x18  \x01(\b:\x04trueR\x1avocabularyOutputPieceScore\x12.\n" +
	"\x10hard_vocab_limit\x18! \x01(\b:\x04trueR\x0ehardVocabLimit\x12)\n" +
	"\ruse_all_vocab\x18\" \x01(\b:\x05falseR\vuseAllVocab\x12\x18\n" +
	"\x06unk_id\x18( \x01(\x05:\x010R\x05unkId\x12\x18\n" +
	"\x06bos_id\x18) \x01(\x05:\x011R\x05bosId\x12\x18\n" +
	"\x06eos_id\x18* \x01(\x05:\x012R\x05eosId\x12\x19\n" +
	"\x06pad_id\x18+ \x01(\x05:\x02-1R\x05padId\x12\"\n" +
	"\tunk_piece\x18- \x01(\t:\x05<unk>R\bunkPiece\x12 \n" +
	"\tbos_piece\x18. \x01(\t:\x03<s>R\bbosPiece\x12!\n" +
	"\teos_piece\x18/ \x01(\t:\x04</s>R\beosPiece\x12\"\n" +
	"\tpad_piece\x180 \x01(\t:\x05<pad>R\bpadPiece\x12&\n" +
	"\vunk_surface\x18, \x01(\t:\x05 ⁇ R\n" +
	"unkSurface\x12F\n" +
	"\x1ctrain_extremely_large_corpus\x181 \x01(\b:\x05falseR\x19trainExtremelyLargeCorpus\x12:\n" +
	"\x18seed_sentencepieces_file\x186 \x01(\t:\x00R\x16seedSentencepiecesFile\"5\n" +
	"\tModelType\x12\v\n" +
	"\aUNIGRAM\x10\x01\x12\a\n" +
	"\x03BPE\x10\x02\x12\b\n" +
	"\x04WORD\x10\x03\x12\b\n" +
	"\x04CHAR\x10\x04*\t\b\xc8\x01\x10\x80\x80\x80\x80\x02\"\xbd\x02\n" +
	"\x0eNormalizerSpec\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x121\n" +
	"\x14precompiled_charsmap\x18\x02 \x01(\fR\x13precompiledCharsmap\x12.\n" +
	"\x10add_dummy_prefix\x18\x03 \x01(\b:\x04trueR\x0eaddDummyPrefix\x12>\n" +
	"\x18remove_extra_whitespaces\x18\x04 \x01(\b:\x04trueR\x16removeExtraWhitespaces\x123\n" +
	"\x12escape_whitespaces\x18\x05 \x01(\b:\x04trueR\x11escapeWhitespaces\x124\n" +
	"\x16normalization_rule_tsv\x18\x06 \x01(\tR\x14normalizationRuleTsv*\t\b\xc8\x01\x10\x80\x80\x80\x80\x02\"\x93\x01\n" +
	"\fSelfTestData\x12<\n" +
	"\asamples\x18\x01 \x03(\v2\".sentencepiece.SelfTestData.SampleR\asamples\x1a:\n" +
	"\x06Sample\x12\x14\n" +
	"\x05input\x18\x01 \x01(\tR\x05input\x12\x1a\n" +
	"\bexpected\x18\x02 \x01(\tR\bexpected*\t\b\xc8\x01\x10\x80\x80\x80\x80\x02\"\xd7\x04\n" +
	"\n" +
	"ModelProto\x12?\n" +
	"\x06pieces\x18\x01 \x03(\v2'.sentencepiece.ModelProto.SentencePieceR\x06pieces\x12=\n" +
	"\ftrainer_spec\x18\x02 \x01(\v2\x1a.sentencepiece.TrainerSpecR\vtrainerSpec\x12F\n" +
	"\x0fnormalizer_spec\x18\x03 \x01(\v2\x1d.sentencepiece.NormalizerSpecR\x0enormalizerSpec\x12A\n" +
	"\x0eself_test_data\x18\x04 \x01(\v2\x1b.sentencepiece.SelfTestDataR\fselfTestData\x12J\n" +
	"\x11denormalizer_spec\x18\x05 \x01(\v2\x1d.sentencepiece.NormalizerSpecR\x10denormalizerSpec\x1a\xe6\x01\n" +
	"\rSentencePiece\x12\x14\n" +
	"\x05piece\x18\x01 \x01(\tR\x05piece\x12\x14\n" +
	"\x05score\x18\x02 \x01(\x02R\x05score\x12H\n" +
	"\x04type\x18\x03 \x01(\x0e2,.sentencepiece.ModelProto.SentencePiece.Type:\x06NORMALR\x04type\"T\n" +
	"\x04Type\x12\n" +
	"\n" +
	"\x06NORMAL\x10\x01\x12\v\n" +
	"\aUNKNOWN\x10\x02\x12\v\n" +
	"\aCONTROL\x10\x03\x12\x10\n" +
	"\fUSER_DEFINED\x10\x04\x12\b\n" +
	"\x04BYTE\x10\x06\x12\n" +
	"\n" +
	"\x06UNUSED\x10\x05*\t\b\xc8\x01\x10\x80\x80\x80\x80\x02*\t\b\xc8\x01\x10\x80\x80\x80\x80\x02B\x02H\x03"

var (
	file_sentencepiece_model_proto_rawDescOnce sync.Once
	file_sentencepiece_model_proto_rawDescData []byte
)

func file_sentencepiece_model_proto_rawDescGZIP() []byte {
	file_sentencepiece_model_proto_rawDescOnce.Do(func() {
		file_sentencepiece_model_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_sentencepiece_model_proto_rawDesc), len(file_sentencepiece_model_proto_rawDesc)))
	})
	return file_sentencepiece_model_proto_rawDescData
}

var file_sentencepiece_model_proto_enumTypes = make([]protoimpl.EnumInfo, 2)
var file_sentencepiece_model_proto_msgTypes = make([]protoimpl.MessageInfo, 6)
var file_sentencepiece_model_proto_goTypes = []any{
	(TrainerSpec_ModelType)(0),         // 0: sentencepiece.TrainerSpec.ModelType
	(ModelProto_SentencePiece_Type)(0), // 1: sentencepiece.ModelProto.SentencePiece.Type
	(*TrainerSpec)(nil),                // 2: sentencepiece.TrainerSpec
	(*NormalizerSpec)(nil),             // 3: sentencepiece.NormalizerSpec
	(*SelfTestData)(nil),               // 4: sentencepiece.SelfTestData
	(*ModelProto)(nil),                 // 5: sentencepiece.ModelProto
	(*SelfTestData_Sample)(nil),        // 6: sentencepiece.SelfTestData.Sample
	(*ModelProto_SentencePiece)(nil),   // 7: sentencepiece.ModelProto.SentencePiece
}
var file_sentencepiece_model_proto_depIdxs = []int32{
	0, // 0: sentencepiece.TrainerSpec.model_type:type_name -> sentencepiece.TrainerSpec.ModelType
	6, // 1: sentencepiece.SelfTestData.samples:type_name -> sentencepiece.SelfTestData.Sample
	7, // 2: sentencepiece.ModelProto.pieces:type_name -> sentencepiece.ModelProto.SentencePiece
	2, // 3: sentencepiece.ModelProto.trainer_spec:type_name -> sentencepiece.TrainerSpec
	3, // 4: sentencepiece.ModelProto.normalizer_spec:type_name -> sentencepiece.NormalizerSpec
	4, // 5: sentencepiece.ModelProto.self_test_data:type_name -> sentencepiece.SelfTestData
	3, // 6: sentencepiece.ModelProto.denormalizer_spec:type_name -> sentencepiece.NormalizerSpec
	1, // 7: sentencepiece.ModelProto.SentencePiece.type:type_name -> sentencepiece.ModelProto.SentencePiece.Type
	8, // [8:8] is the sub-list for method output_type
	8, // [8:8] is the sub-list for method input_type
	8, // [8:8] is the sub-list for extension type_name
	8, // [8:8] is the sub-list for extension extendee
	0, // [0:8] is the sub-list for field type_name
}

func init() { file_sentencepiece_model_proto_init() }
func file_sentencepiece_model_proto_init() {
	if File_sentencepiece_model_proto != nil {
		return
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_sentencepiece_model_proto_rawDesc), len(file_sentencepiece_model_proto_rawDesc)),
			NumEnums:      2,
			NumMessages:   6,
			NumExtensions: 0,
			NumServices:   0,
		},
		GoTypes:           file_sentencepiece_model_proto_goTypes,
		DependencyIndexes: file_sentencepiece_model_proto_depIdxs,
		EnumInfos:         file_sentencepiece_model_proto_enumTypes,
		MessageInfos:      file_sentencepiece_model_proto_msgTypes,
	}.Build()
	File_sentencepiece_model_proto = out.File
	file_sentencepiece_model_proto_goTypes = nil
	file_sentencepiece_model_proto_depIdxs = nil
}
